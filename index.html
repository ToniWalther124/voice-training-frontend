<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>Voice Training – Open Mic</title>
    <style>
      body { font-family: system-ui, Arial; max-width: 760px; margin: 40px auto; padding: 0 16px; }
      button { font-size: 16px; padding: 12px 14px; margin-right: 8px; }
      #log { white-space: pre-wrap; background: #f5f5f5; padding: 12px; border-radius: 8px; margin-top: 12px; }
      .row { display:flex; gap:8px; flex-wrap:wrap; margin: 12px 0; }
    </style>
  </head>
  <body>
    <h1>Open Mic Test</h1>
    <p>Start verbindet per WebRTC mit OpenAI Realtime und holt sich den ephemeren Key über <code>/api/session</code>.</p>

    <div class="row">
      <button id="start">Start</button>
      <button id="stop" disabled>Stop</button>
    </div>

    <div id="log"></div>
    <audio id="remoteAudio" autoplay playsinline></audio>

    <script>
      const logEl = document.getElementById("log");
      const startBtn = document.getElementById("start");
      const stopBtn  = document.getElementById("stop");
      const remoteAudio = document.getElementById("remoteAudio");

      let pc, dc, localStream;

      function log(msg) { logEl.textContent += msg + "\n"; }

      async function getEphemeralKey() {
  const r = await fetch("/api/session2");

  // erst als text lesen, dann versuchen JSON zu parsen
  const raw = await r.text();

  let data;
  try {
    data = JSON.parse(raw);
  } catch {
    throw new Error("Session endpoint returned non-JSON: " + raw.slice(0, 200));
  }

  if (!r.ok) {
    throw new Error(data.error || "Failed to get session");
  }

  // Backend kann entweder {value: "..."} direkt liefern oder {client_secret:{value:"..."}}
  return data.value || data?.client_secret?.value;

      }

      startBtn.onclick = async () => {
        try {
          logEl.textContent = "";
          startBtn.disabled = true;
          stopBtn.disabled = false;

          const ek = await getEphemeralKey();
          log("Got ephemeral key ✅");

          pc = new RTCPeerConnection();

          pc.ontrack = (e) => {
            remoteAudio.srcObject = e.streams[0];
          };

          dc = pc.createDataChannel("oai-events");
          dc.onopen = () => log("DataChannel open ✅");
          dc.onmessage = (e) => log("event: " + e.data);

          localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          localStream.getTracks().forEach(track => pc.addTrack(track, localStream));
          log("Microphone enabled ✅");

          const offer = await pc.createOffer();
          await pc.setLocalDescription(offer);

          const sdpResponse = await fetch("https://api.openai.com/v1/realtime", {
            method: "POST",
            headers: {
              "Authorization": "Bearer " + ek,
              "Content-Type": "application/sdp"
            },
            body: offer.sdp
          });

          if (!sdpResponse.ok) {
            const t = await sdpResponse.text();
            throw new Error("Realtime SDP failed: " + t);
          }

          const answerSdp = await sdpResponse.text();
          await pc.setRemoteDescription({ type: "answer", sdp: answerSdp });

          log("WebRTC connected ✅ Speak now…");

        } catch (err) {
          log("ERROR: " + (err?.message || err));
          startBtn.disabled = false;
          stopBtn.disabled = true;
        }
      };

      stopBtn.onclick = () => {
        stopBtn.disabled = true;
        startBtn.disabled = false;

        try { if (dc) dc.close(); } catch {}
        try { if (pc) pc.close(); } catch {}
        try { if (localStream) localStream.getTracks().forEach(t => t.stop()); } catch {}

        log("Stopped.");
      };
    </script>
  </body>
</html>
